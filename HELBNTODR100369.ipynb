{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HELBNTODR100369.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfVAGoYlut6nKcURcWE5Vf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sailkargutkar/Python-Projects/blob/HELBNTODR100369/HELBNTODR100369.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypTRi5KpX7vz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "cf0ef493-4358-4b14-acc5-4b55a55af572"
      },
      "source": [
        "!pip install scattertext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scattertext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/80/db3ecd7d594aec7f3bb35382f9c726d490e3f3bbaca3100d90d29ebf2e40/scattertext-0.0.2.66-py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2MB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from scattertext) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from scattertext) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.0.5)\n",
            "Collecting mock\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/74/d72daf8dff5b6566db857cfd088907bb0355f5dd2914c4b3ef065c790735/mock-4.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scattertext) (1.18.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->scattertext) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->scattertext) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->scattertext) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->scattertext) (2.8.1)\n",
            "Installing collected packages: mock, scattertext\n",
            "Successfully installed mock-4.0.2 scattertext-0.0.2.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC34bb52fd5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e5afe13f-c743-48e2-a1c6-656d7f291a4e"
      },
      "source": [
        "!pip install \"git+https://github.com/facebookresearch/fastText.git\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/fastText.git\n",
            "  Cloning https://github.com/facebookresearch/fastText.git to /tmp/pip-req-build-vxh0dqvg\n",
            "  Running command git clone -q https://github.com/facebookresearch/fastText.git /tmp/pip-req-build-vxh0dqvg\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (2.5.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (49.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext==0.9.2) (1.18.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3012506 sha256=0187dfa56ff59239f9e242e0811f5a38ee6d72c2aa6ce5a5ccb050a265ab52fd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tn_a9e5z/wheels/69/f8/19/7f0ab407c078795bc9f86e1f6381349254f86fd7d229902355\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWpVu8uNaOUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2764d737-3031-4799-c799-566458717eab"
      },
      "source": [
        "import fasttext.util\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import scattertext as st\n",
        "import spacy\n",
        "\n",
        "from keras import layers\n",
        "from keras.layers import Dropout \n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from scattertext import CorpusFromPandas, produce_scattertext_explorer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPBrO6jqftRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "685af451-bcd8-44d6-edab-0bdba4954555"
      },
      "source": [
        "df = pd.read_csv('/content/agr_en_train.csv', names=['unique_id','text','aggression-level'], sep=',')\n",
        "print(df.iloc[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique_id                                 facebook_corpus_msr_1723796\n",
            "text                Well said sonu..you have courage to stand agai...\n",
            "aggression-level                                                  OAG\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mJE0EjkleNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22bab833-e1a5-4094-e6aa-20bcb948efef"
      },
      "source": [
        "df.isna().values.any()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KAgJqT4lhI9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "e02dda03-c697-4590-8624-bb2d531a991b"
      },
      "source": [
        "df['aggression-level'].value_counts() "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NAG    5051\n",
              "CAG    4240\n",
              "OAG    2708\n",
              "Name: aggression-level, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuQHdit71SHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "b08248ae-382f-46e8-a39e-d4cbf0afc41f"
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "df['parsed'] = df.text.apply(nlp)\n",
        "data = st.CorpusFromParsedDocuments(df, category_col='aggression-level', \n",
        "                                      parsed_col='parsed').build().remove_terms(nlp.Defaults.stop_words, ignore_absences=True)\n",
        "\n",
        "freq_df = data.get_term_freq_df()\n",
        "oag_tw = freq_df.sort_values(by=['OAG freq'], ascending=False)\n",
        "oag_tw = oag_tw.drop(oag_tw.columns[[1,2]], axis=1)\n",
        "nag_tw = freq_df.sort_values(by=['NAG freq'], ascending=False)\n",
        "nag_tw = nag_tw.drop(nag_tw.columns[[0,2]], axis=1)\n",
        "cag_tw = freq_df.sort_values(by=['CAG freq'], ascending=False)\n",
        "cag_tw = cag_tw.drop(cag_tw.columns[[0,1]], axis=1)\n",
        "\n",
        "print(oag_tw.head())\n",
        "print(nag_tw.head())\n",
        "print(cag_tw.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        OAG freq\n",
            "term            \n",
            "u            420\n",
            "india        396\n",
            "people       372\n",
            "like         317\n",
            "indian       279\n",
            "        NAG freq\n",
            "term            \n",
            "india        616\n",
            "people       357\n",
            "good         355\n",
            "indian       350\n",
            "like         315\n",
            "        CAG freq\n",
            "term            \n",
            "people       554\n",
            "india        493\n",
            "u            466\n",
            "bjp          357\n",
            "like         337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nP_u8cn1TYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['aggression-level'] = df['aggression-level'].replace({ 'OAG' : 0, 'NAG' : 1, 'CAG' : 2 }) \n",
        "labels = df['aggression-level'].values\n",
        "labels = to_categorical(labels, num_classes = 3)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOwfq4pB1U39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0804db12-2d4c-4766-d3ca-60b3e0a47b96"
      },
      "source": [
        "fasttext.util.download_model('en', if_exists='ignore') \n",
        "ft = fasttext.load_model('cc.en.300.bin')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oupcrnxx1WDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "review_length = 100\n",
        "data_count = len(df)\n",
        "dims = ft.get_dimension()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIZVOd4q1XGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_to_vector(text):\n",
        "\n",
        "  text = text.replace('&', ' and ')\n",
        "  text = text.replace('@', ' at ')\n",
        "  text = re.sub(r'[^\\x41-\\x7f]',r' ',text)\n",
        "  text = text.lower().split()\n",
        "\n",
        "  window = text[-review_length:]\n",
        "  \n",
        "  vectors = np.zeros((review_length, dims))\n",
        "\n",
        "  for i, word in enumerate(window):\n",
        "      vectors[i, :] = ft.get_word_vector(word).astype('float32')\n",
        "\n",
        "  return vectors\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH0Jg_mY1YTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_word_embedding(df):\n",
        "\n",
        "    word_embedding = np.zeros((len(df), review_length, dims), dtype='float32')\n",
        "\n",
        "    for i, review in enumerate(df['text'].values):\n",
        "        word_embedding[i, :] = text_to_vector(review)\n",
        "\n",
        "    return word_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnFyEckm1ZqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding = create_word_embedding(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht6msjRFJyT9",
        "colab_type": "text"
      },
      "source": [
        "Hyperparameter tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGH2Zy_QJy4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = DecisionTreeClassifier() #Decision tree classifier\n",
        "\n",
        "# Hyperparameter Optimization\n",
        "parameters = {'max_features': ['log2', 'sqrt','auto'], \n",
        "              'criterion': ['entropy', 'gini'],\n",
        "              'max_depth': [2, 3, 5, 10, 50], \n",
        "              'min_samples_split': [2, 3, 50, 100],\n",
        "              'min_samples_leaf': [1, 5, 8, 10]\n",
        "             }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXnA3cDVJ07i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "objectG = GridSearchCV(classifier, parameters) # Grid search\n",
        "objectG = objectG.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XgV3TtcJ4Ct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set the clf to the best combination of parameters\n",
        "classifier = objectG.best_estimator_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDfz0XkyJ9Pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train the model using the training sets \n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXxM4D1x1ay2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(embedding, labels, test_size=0.20, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H9Ax7vL1b_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_text_classifier():\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv1D(128, 5, activation='relu', input_shape=(review_length, dims)))\n",
        "    model.add(layers.GlobalAveragePooling1D())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "    model.add(layers.Dense(3, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tI4y1mr1dP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = cnn_text_classifier()\n",
        "modHistory = model.fit(X_train, y_train, epochs=10, verbose=False, validation_data=(X_test, y_test), batch_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4mYVrC11eq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr1Yhp9Y1f8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score, precision_score\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_pred2 = np.argmax(y_test, axis=1)\n",
        "\n",
        "cm=confusion_matrix(y_pred2,y_pred)\n",
        "print(cm)\n",
        "\n",
        "score = f1_score(y_pred2,y_pred,average=\"micro\")\n",
        "print(\"F1 score : \", score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1wkdWyM1hGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model accuracy and loss graphs\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(modHistory.history['accuracy'])\n",
        "plt.plot(modHistory.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show() #plotting the accuracy  vs the number of epochs\n",
        "\n",
        "plt.plot(modHistory.history['loss'])\n",
        "plt.plot(modHistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show() #plotting the loss vs the number of epochs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}